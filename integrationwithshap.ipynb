{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[here the source](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%20insights.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume we have the dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgboost(X, y):\n",
    "    \"\"\"Train an XGBoost model with early stopping.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgboost.DMatrix(X_test, label=y_test)\n",
    "    model = xgboost.train(\n",
    "        {\"eta\": 0.001, \"subsample\": 0.5, \"max_depth\": 2, \"objective\": \"reg:logistic\"},\n",
    "        dtrain,\n",
    "        num_boost_round=200000,\n",
    "        evals=((dtest, \"test\"),),\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "clust = shap.utils.hclust(X, y, linkage=\"single\")\n",
    "shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values, ylabel=\"SHAP value\\n(higher means more likely to renew)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original goal for this model was to predict customer retention, which is useful for projects like estimating future revenue for financial planning. Since users reporting more bugs are in fact more likely to renew, capturing this relationship in the model is helpful for prediction. As long as our model has good fit out-of-sample, we should be able to provide finance with a good prediction, and therefore shouldn’t worry about the direction of this relationship in the model.\n",
    "\n",
    "This is an example of a class of tasks called prediction tasks. In a prediction task, the goal is to predict an outcome Y (e.g. renewals) given a set of features X. A key component of a prediction exercise is that we only care that the prediction model(X) is close to Y in data distributions similar to our training set. A simple correlation between X and Y can be helpful for these types of predictions.\n",
    "\n",
    "However, suppose a second team picks up our prediction model with the new goal of determining what actions our company can take to retain more customers. This team cares a lot about how each X feature relates to Y, not just in our training distribution, but the counterfactual scenario produced when the world changes. In that use case, it is no longer sufficient to identify a stable correlation between variables; this team wants to know whether manipulating feature X will cause a change in Y. Picture the face of the chief of engineering when you tell him that you want him to introduce new bugs to increase customer renewals!\n",
    "\n",
    "This is an example of a class of tasks called causal tasks. In a causal task, we want to know how changing an aspect of the world X (e.g bugs reported) affects an outcome Y (renewals). In this case, it’s critical to know whether changing X causes an increase in Y, or whether the relationship in the data is merely correlational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful tool to understanding causal relationships is writing down a causal graph of the data generating process we’re interested in. A causal graph of our example illustrates why the robust predictive relationships picked up by our XGBoost customer retention model differ from the causal relationships of interest to the team that wants to plan interventions to increase retention. This graph is just a summary of the true data generating mechanism (which is defined above). Solid ovals represent features that we observe, while dashed ovals represent hidden features that we don’t measure. Each feature is a function of all the features with an arrow to it, plus some random effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "names = [\n",
    "    \"Bugs reported\",\n",
    "    \"Monthly usage\",\n",
    "    \"Sales calls\",\n",
    "    \"Economy\",\n",
    "    \"Discount\",\n",
    "    \"Last upgrade\",\n",
    "    \"Ad spend\",\n",
    "    \"Interactions\",\n",
    "]\n",
    "g = graphviz.Digraph()\n",
    "for name in names:\n",
    "    g.node(name, fontsize=\"10\")\n",
    "g.node(\"Product need\", style=\"dashed\", fontsize=\"10\")\n",
    "g.node(\"Bugs faced\", style=\"dashed\", fontsize=\"10\")\n",
    "g.node(\"Did renew\", style=\"filled\", fontsize=\"10\")\n",
    "\n",
    "g.edge(\"Product need\", \"Did renew\")\n",
    "g.edge(\"Product need\", \"Discount\")\n",
    "g.edge(\"Product need\", \"Bugs reported\")\n",
    "g.edge(\"Product need\", \"Monthly usage\")\n",
    "g.edge(\"Discount\", \"Did renew\")\n",
    "g.edge(\"Monthly usage\", \"Bugs faced\")\n",
    "g.edge(\"Monthly usage\", \"Did renew\")\n",
    "g.edge(\"Monthly usage\", \"Ad spend\")\n",
    "g.edge(\"Economy\", \"Did renew\")\n",
    "g.edge(\"Sales calls\", \"Did renew\")\n",
    "g.edge(\"Sales calls\", \"Product need\")\n",
    "g.edge(\"Sales calls\", \"Interactions\")\n",
    "g.edge(\"Interactions\", \"Did renew\")\n",
    "g.edge(\"Bugs faced\", \"Did renew\")\n",
    "g.edge(\"Bugs faced\", \"Bugs reported\")\n",
    "g.edge(\"Last upgrade\", \"Did renew\")\n",
    "g.edge(\"Last upgrade\", \"Ad spend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of relationships in this graph, but the first important concern is that some of the features we can measure are influenced by unmeasured confounding features like product need and bugs faced. For example, users who report more bugs are encountering more bugs because they use the product more, and they are also more likely to report those bugs because they need the product more. Product need has its own direct causal effect on renewal. Because we can’t directly measure product need, the correlation we end up capturing in predictive models between bugs reported and renewal combines a small negative direct effect of bugs faced and a large positive confounding effect from product need. The figure below plots the SHAP values in our example against the true causal effect of each feature (known in this example since we generated the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_effects(generative_model, num_samples=100, columns=None, max_points=20, logit=True, seed=0):\n",
    "    \"\"\"Helper function to compute the true marginal causal effects.\"\"\"\n",
    "    X = generative_model(num_samples)\n",
    "    if columns is None:\n",
    "        columns = X.columns\n",
    "    ys = [[] for _ in columns]\n",
    "    xs = [X[c].values for c in columns]\n",
    "    xs = np.sort(xs, axis=1)\n",
    "    xs = [xs[i] for i in range(len(xs))]\n",
    "    for i, c in enumerate(columns):\n",
    "        xs[i] = np.unique([np.nanpercentile(xs[i], v, method=\"nearest\") for v in np.linspace(0, 100, max_points)])\n",
    "        for x in xs[i]:\n",
    "            Xnew = generative_model(num_samples, fixed={c: x}, seed=seed)\n",
    "            val = Xnew[\"Did renew\"].mean()\n",
    "            if logit:\n",
    "                val = scipy.special.logit(val)\n",
    "            ys[i].append(val)\n",
    "        ys[i] = np.array(ys[i])\n",
    "    ys = [ys[i] - ys[i].mean() for i in range(len(ys))]\n",
    "    return list(zip(xs, ys))\n",
    "\n",
    "\n",
    "shap.plots.scatter(\n",
    "    shap_values,\n",
    "    ylabel=\"SHAP value\\n(higher means more likely to renew)\",\n",
    "    overlay={\"True causal effects\": marginal_effects(generator, 10000, X.columns)},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
