{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helpermodules.memory_handling import PickleHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = PickleHelper.pickle_load(filename).obj\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analysis\n",
    "- Plotting sales\n",
    "- Sales based on state\n",
    "- Payment type\n",
    "- CSAT percentages\n",
    "- Average time delivery\n",
    "- CSAT and delivery time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the order_purchase_timestamp is in datetime format\n",
    "merged_df['order_purchase_timestamp'] = pd.to_datetime(merged_df['order_purchase_timestamp'])\n",
    "\n",
    "# Extract year and month for aggregation\n",
    "merged_df['year_month'] = merged_df['order_purchase_timestamp'].dt.to_period('M')\n",
    "\n",
    "# Aggregate data by year and month\n",
    "sales_trends = merged_df.groupby('year_month').size()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sales_trends.plot(kind='line', marker='o')\n",
    "plt.title('Sales Trends Over Time (Monthly)')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales based on state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by customer state\n",
    "state_sales = merged_df.groupby('customer_state').size().sort_values(ascending=False)\n",
    "\n",
    "# Plotting sales distribution by state\n",
    "plt.figure(figsize=(15, 6))\n",
    "state_sales.plot(kind='bar')\n",
    "plt.title('Geographic Distribution of Sales by State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payment type\n",
    "merged_df['payment_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Payment Type Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of CSAT percentages on pie chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "merged_df['satisfaction'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Distribution of CSAT Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Analysis\n",
    "- Total order value by category\n",
    "- Control Chart for Daily Average Time to Delivery\n",
    "- Identifying top 10 features with highest correlation with 'satisfaction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total order value by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total order value by category\n",
    "order_value_by_category = merged_df.groupby('product_category_name_english')['order_value'].sum()\n",
    "total_order_value = order_value_by_category.sum()\n",
    "order_value_by_category_percent = (order_value_by_category / total_order_value).cumsum() * 100\n",
    "\n",
    "# Correcting the approach for the Pareto Chart of Order Value by Product Category\n",
    "\n",
    "# Sorting the order values by category in descending order\n",
    "sorted_order_value_by_category = order_value_by_category.sort_values(ascending=False)\n",
    "cumulative_order_value_percent = sorted_order_value_by_category.cumsum() / total_order_value * 100\n",
    "\n",
    "# Recreating the Pareto Chart with the correct approach\n",
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "sorted_order_value_by_category.plot(kind='bar', ax=ax, color='green')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(cumulative_order_value_percent.index, cumulative_order_value_percent.values, color='red', marker='D', ms=7)\n",
    "ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "# Adding lines for the 80% threshold\n",
    "ax2.axhline(80, color='green', linestyle='--', linewidth=2)\n",
    "category_80_idx_corrected = cumulative_order_value_percent[cumulative_order_value_percent >= 80].index[0]\n",
    "category_80_position_corrected = cumulative_order_value_percent.index.get_loc(category_80_idx_corrected)\n",
    "\n",
    "ax.axvline(category_80_position_corrected, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.tick_params(axis='y', colors='orange')\n",
    "ax2.tick_params(axis='y', colors='red')\n",
    "ax.set_xlabel('Product Category')\n",
    "ax.set_ylabel('Total Order Value', color='orange')\n",
    "ax2.set_ylabel('Cumulative Percentage', color='red')\n",
    "plt.title('Pareto Chart of Order Value by Product Category with 80/20 Threshold')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareto Chart of Order Value by Product Category with 80/20 Threshold: A small number of categories generate most of the revenue, showing market focus areas or best-sellers.Â¶\n",
    "\n",
    "We can use above insight in targeted Marketing efforts by :\n",
    "Allocate more budget to advertise the top-performing product categories that contribute most to your sales volume to maximize ROI.\n",
    "Create bundles or promotions that include high-value items with other products to increase the overall order value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Chart for Daily Average Time to Delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdates\n",
    "\n",
    "# Preparing data for Control Chart: Calculate daily average time to delivery\n",
    "daily_delivery_times = merged_df.copy()\n",
    "daily_delivery_times['order_approved_at'] = pd.to_datetime(daily_delivery_times['order_approved_at'])\n",
    "daily_delivery_times.set_index('order_approved_at', inplace=True)\n",
    "daily_avg_delivery_time = daily_delivery_times['time_to_delivery'].resample('D').mean().dropna()\n",
    "\n",
    "# Control Chart calculations\n",
    "mean_delivery_time = daily_avg_delivery_time.mean()\n",
    "std_dev_delivery_time = daily_avg_delivery_time.std()\n",
    "upper_control_limit = mean_delivery_time + (std_dev_delivery_time * 3)\n",
    "lower_control_limit = mean_delivery_time - (std_dev_delivery_time * 3)\n",
    "\n",
    "# Plotting the Control Chart\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "daily_avg_delivery_time.plot(ax=ax, marker='o', linestyle='-', color='blue', markersize=4)\n",
    "ax.axhline(mean_delivery_time, color='green', linestyle='--')\n",
    "ax.axhline(upper_control_limit, color='red', linestyle='--')\n",
    "ax.axhline(lower_control_limit, color='red', linestyle='--')\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_title('Control Chart for Daily Average Time to Delivery')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Average Time to Delivery (Days)')\n",
    "ax.legend(['Daily Avg Time to Delivery', 'Mean', 'Upper Control Limit', 'Lower Control Limit'])\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying top 10 features with highest correlation with 'satisfaction'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying top 10 features with highest correlation with 'satisfaction'\n",
    "# Select only the numeric columns for correlation calculation\n",
    "numeric_cols = merged_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute the correlation matrix for numeric columns only\n",
    "corr_matrix = numeric_cols.corr()\n",
    "\n",
    "# Print the top 10 features correaltion score\n",
    "print(corr_matrix['satisfaction'].sort_values(ascending=False)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correlation threshold\n",
    "threshold = 0.05\n",
    "\n",
    "# Get the features with correlation greater than 7% or less than -7% with 'satisfaction'\n",
    "high_corr_features = corr_matrix.index[(corr_matrix['satisfaction'].abs() > threshold) & (corr_matrix.index != 'satisfaction')].tolist()\n",
    "\n",
    "# Print the highly correlated features\n",
    "print(high_corr_features)\n",
    "\n",
    "# check data types for top 10 features\n",
    "merged_df[high_corr_features].dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to take only 5 features\n",
    "top_4_features = ['payment_value', 'time_to_delivery', 'estimated_vs_actual_shipping', 'late_delivery']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Selecting only the top 6 features\n",
    "top_6_features = ['estimated_vs_actual_shipping', 'order_month', 'order_hour', 'price', 'payment_sequential', 'order_value', 'payment_installments']\n",
    "X = merged_df[top_4_features]\n",
    "y = merged_df['satisfaction']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Applying ColumnTransformer to preprocess the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, top_4_features)]\n",
    ")\n",
    "\n",
    "# Preprocessing the data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=50),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10, min_samples_split=10, min_samples_leaf=4),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to fit models, make predictions, and evaluate them\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Plotting confusion matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    evaluate_model(model, X_train_preprocessed, y_train, X_test_preprocessed, y_test, model_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
