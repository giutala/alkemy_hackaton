{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methodoly hypothesis: \n",
    "- We will not work with deep learning as it does not provide insights into the patterns. <- no explainability.We will also conclude with an analysis in explainability. \n",
    "- We will work with regression and likeability (⁠xgboost regressor e classification)- and ARIMA for prediction.\n",
    "- Qualitative data analysis must also identify outliers \n",
    "- If too many features, proceed with [feature selection](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n",
    "- Check for class imbalance: If one class is much less frequent than others, traditional accuracy may not be a good indicator of performance.\n",
    "- Use appropriate metrics: Consider using F1 score or precision instead of accuracy to evaluate your model, especially for the underrepresented class.\n",
    "- Visualize performance: Creating an ROC curve helps to understand the trade-offs between true positive and false positive rates across different threshold settings. \n",
    "- We will validate the model with bootstrap if there is time. \n",
    "- Use library [SHAP](https://shap.readthedocs.io/en/latest/index.html) \n",
    "- Using XGboost, we will make analysis of feature importance, which derive from feature trees\n",
    "- Clustering will be done in the end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Insights \n",
    "Our aim is to uncover insights into customer satisfaction, delivery efficiency, and purchasing patterns through statistical analysis, machine learning, and data visualization.\n",
    "\n",
    "## Analyzed Questions\n",
    "- Sales Trends Over Time: Identifying periods of high demand to inform inventory and marketing strategies.\n",
    "- Popular Product Categories: Highlighting top-selling categories to prioritize stock and marketing efforts.\n",
    "- Geographic Distribution of Sales: Tailoring logistics strategies to improve delivery times in key markets.\n",
    "- Influence of Payment Types on Purchases: Enhancing the checkout process to increase conversion rates.\n",
    "- Customer Satisfaction Distribution: Identifying improvement areas in product quality, service, and delivery.\n",
    "- Factors Affecting Delivery Times: Analyzing and optimizing delivery performance to reduce late deliveries.\n",
    "- Time to Delivery vs. Customer Satisfaction: Examining the impact of delivery times on satisfaction levels.\n",
    "- Key Predictors of Customer Satisfaction: Using machine learning to focus efforts on aspects crucial to customers.\n",
    "- Actual vs. Estimated Delivery Times: Assessing delivery estimate accuracy and its satisfaction impact.\n",
    "- Strategies for Business Improvement: Formulating recommendations based on data insights to enhance customer experience and business performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors that influence customer behavior\n",
    "1. Demographic; \n",
    "2. Psychographic;\n",
    "3. Social; \n",
    "4. Cultural; \n",
    "5. Economical; \n",
    "\n",
    "The following code addresses all of these, given a dataset and the following hypothesis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "def load_datasets(dataset_names, base_path):\n",
    "    datasets = {}\n",
    "    for name in dataset_names:\n",
    "        file_path = os.path.join(base_path, name + '.csv')\n",
    "        try:\n",
    "            datasets[name] = pd.read_csv(file_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            datasets[name] = None\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming /kaggle/input/brazilian-ecommerce/ is the correct directory\n",
    "base_path = '/kaggle/input/brazilian-ecommerce/'\n",
    "\n",
    "# Dataset names\n",
    "dataset_names = [\n",
    "    'olist_customers_dataset', \n",
    "    'olist_order_items_dataset', \n",
    "    'olist_order_payments_dataset', \n",
    "    'olist_order_reviews_dataset', \n",
    "    'olist_orders_dataset', \n",
    "    'olist_sellers_dataset', \n",
    "    'olist_products_dataset', \n",
    "    'product_category_name_translation'\n",
    "]\n",
    "\n",
    "# Assuming you have a function load_datasets that loads the datasets given the names and path\n",
    "datasets = load_datasets(dataset_names, base_path)\n",
    "\n",
    "# Displaying the first few rows of each dataset to understand their structure\n",
    "for name, df in datasets.items():\n",
    "    if df is not None:\n",
    "        print(f\"\\nFirst few rows of {name}:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"Failed to load {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_datasets(datasets):\n",
    "    # Start by merging orders with customers\n",
    "    merged = pd.merge(datasets['olist_orders_dataset'], datasets['olist_customers_dataset'], on='customer_id', how='left')\n",
    "\n",
    "    # Add other datasets with the correct merge keys\n",
    "    merge_keys = {\n",
    "        'order_items': 'order_id',\n",
    "        'order_payments': 'order_id',\n",
    "        'order_reviews': 'order_id',\n",
    "        'sellers': 'seller_id',\n",
    "        'products': 'product_id',\n",
    "        'product_category_name_translation': 'product_category_name'  # Make sure this dataset is loaded correctly\n",
    "    }\n",
    "\n",
    "    for name, key in merge_keys.items():\n",
    "        if name in datasets:\n",
    "            merged = pd.merge(merged, datasets[name], on=key, how='left')\n",
    "\n",
    "    return merged\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load individual datasets\n",
    "olist_customers_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_customers_dataset.csv')\n",
    "order_items_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_items_dataset.csv')\n",
    "order_payments_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_payments_dataset.csv')\n",
    "order_reviews_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv')\n",
    "olist_orders_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_orders_dataset.csv')\n",
    "sellers_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_sellers_dataset.csv')\n",
    "products_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_products_dataset.csv')\n",
    "product_category_name_translation_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/product_category_name_translation.csv')\n",
    "\n",
    "# Define the datasets dictionary\n",
    "datasets = {\n",
    "    'olist_customers_dataset': olist_customers_df,\n",
    "    'order_items': order_items_df,\n",
    "    'order_payments': order_payments_df,\n",
    "    'order_reviews': order_reviews_df,\n",
    "    'olist_orders_dataset': olist_orders_df,\n",
    "    'sellers': sellers_df,\n",
    "    'products': products_df,\n",
    "    'product_category_name_translation': product_category_name_translation_df\n",
    "}\n",
    "\n",
    "# Now, you can call the merge_datasets function with the loaded datasets\n",
    "merged_df = merge_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying data cleaning to new csv file\n",
    "merged_df.to_csv('olist_merged_data.csv', index=False)\n",
    "merged_df.info()\n",
    "# check for duplicates\n",
    "merged_df.duplicated().sum()\n",
    "# check for missing values by percentage in each column\n",
    "merged_df.isnull().sum() / len(merged_df) * 100\n",
    "# drop missing values column with more than 50% missing values\n",
    "merged_df = merged_df.dropna(thresh=len(merged_df) * 0.5, axis=1)\n",
    "\n",
    "# drop rows with missing values\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "# check for missing values by percentage in each column\n",
    "merged_df.info()\n",
    "\n",
    "# Clean and preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Drop columns with more than 50% missing values\n",
    "    df.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    datetime_cols = ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', \n",
    "                    'order_delivered_customer_date', 'order_estimated_delivery_date', \n",
    "                    'shipping_limit_date', 'review_creation_date', 'review_answer_timestamp']\n",
    "    for col in datetime_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Calculate new features\n",
    "    df['time_to_delivery'] = (df['order_delivered_customer_date'] - df['order_approved_at']).dt.days\n",
    "    df['order_processing_time'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.days\n",
    "    df['estimated_vs_actual_shipping'] = (df['order_estimated_delivery_date'] - df['order_delivered_customer_date']).dt.days\n",
    "    df['product_volume_m3'] = (df['product_length_cm'] * df['product_width_cm'] * df['product_height_cm']) / 1000000\n",
    "    df['satisfaction'] = (df['review_score'] >= 4).astype(int)\n",
    "    df['order_value'] = df['price'] + df['freight_value']\n",
    "\n",
    "    # create late delivery flag\n",
    "    df['late_delivery'] = (df['order_delivered_customer_date'] > df['order_estimated_delivery_date']).astype(int)\n",
    "\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # create seasonal features from order_purchase_timestamp\n",
    "    df['order_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['order_day'] = df['order_purchase_timestamp'].dt.dayofweek\n",
    "    df['order_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "\n",
    "    return df\n",
    "\n",
    "merged_df = preprocess_data(merged_df)\n",
    "\n",
    "# drop unnecessary columns\n",
    "merged_df.drop(['product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'review_score', 'seller_zip_code_prefix']\n",
    "               , axis=1, inplace=True) \n",
    "# save the cleaned dataset\n",
    "merged_df.to_csv('olist_merged_data_clean.csv', index=False)\n",
    "\n",
    "merged_df.info()\n",
    "\n",
    "# check summary statistics\n",
    "merged_df.describe()\n",
    "\n",
    "# Check the distribution of the CSAT percentage\n",
    "merged_df['satisfaction'].value_counts() / len(merged_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns from the DataFrame\n",
    "numeric_columns = merged_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Plot the correlation matrix heatmap with numeric columns\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(numeric_columns.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the order_purchase_timestamp is in datetime format\n",
    "merged_df['order_purchase_timestamp'] = pd.to_datetime(merged_df['order_purchase_timestamp'])\n",
    "\n",
    "# Extract year and month for aggregation\n",
    "merged_df['year_month'] = merged_df['order_purchase_timestamp'].dt.to_period('M')\n",
    "\n",
    "# Aggregate data by year and month\n",
    "sales_trends = merged_df.groupby('year_month').size()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sales_trends.plot(kind='line', marker='o')\n",
    "plt.title('Sales Trends Over Time (Monthly)')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by product category\n",
    "category_analysis = merged_df.groupby('product_category_name_english').size().sort_values(ascending=False)\n",
    "\n",
    "# Plotting the top 10 product categories by sales volume\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_analysis.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Product Categories by Sales Volume')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by customer state\n",
    "state_sales = merged_df.groupby('customer_state').size().sort_values(ascending=False)\n",
    "\n",
    "# Plotting sales distribution by state\n",
    "plt.figure(figsize=(15, 6))\n",
    "state_sales.plot(kind='bar')\n",
    "plt.title('Geographic Distribution of Sales by State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payment type\n",
    "merged_df['payment_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Payment Type Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of CSAT percentages on pie chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "merged_df['satisfaction'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Distribution of CSAT Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average delivery time\n",
    "average_delivery_time = merged_df['time_to_delivery'].mean()\n",
    "\n",
    "# Plot the distribution of delivery times\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(merged_df['time_to_delivery'].dropna(), bins=30, kde=True, label='Delivery Time')\n",
    "plt.axvline(average_delivery_time, color='green', linestyle='dashed', linewidth=2, label='Average Delivery Time')\n",
    "plt.text(average_delivery_time + 0.5, plt.ylim()[1] / 2, f'Average: {average_delivery_time:.2f} days', color='green', fontsize=12, ha='left')\n",
    "plt.title('Distribution of Delivery Times')\n",
    "plt.xlabel('Delivery Time (Days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average delivery time\n",
    "average_delivery_time = merged_df['time_to_delivery'].mean()\n",
    "\n",
    "# Initialize counts and labels lists for CSAT categories\n",
    "csat_labels_above, csat_labels_below = [], []\n",
    "csat_counts_above, csat_counts_below = [], []\n",
    "\n",
    "# Filter the DataFrame for CSAT values above and below average time_to_delivery\n",
    "csat_above_avg = merged_df[merged_df['time_to_delivery'] >= average_delivery_time]\n",
    "csat_below_avg = merged_df[merged_df['time_to_delivery'] < average_delivery_time]\n",
    "\n",
    "# Calculate the counts for CSAT categories above average time_to_delivery\n",
    "csat_counts_above = csat_above_avg['satisfaction'].value_counts().tolist()\n",
    "csat_labels_above = csat_above_avg['satisfaction'].value_counts().index.tolist()\n",
    "\n",
    "# Calculate the counts for CSAT categories below average time_to_delivery\n",
    "csat_counts_below = csat_below_avg['satisfaction'].value_counts().tolist()\n",
    "csat_labels_below = csat_below_avg['satisfaction'].value_counts().index.tolist()\n",
    "\n",
    "# Create data for the pie charts\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "\n",
    "# Create the two pie charts\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Pie chart for CSAT above average time_to_delivery\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(csat_counts_above, labels=csat_labels_above, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('CSAT Above Avg Time to Delivery')\n",
    "\n",
    "# Pie chart for CSAT below average time_to_delivery\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(csat_counts_below, labels=csat_labels_below, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('CSAT Below Avg Time to Delivery')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by month to calculate average Time to Delivery and proportion of late deliveries\n",
    "monthly_delivery_stats = merged_df.groupby('order_month').agg(\n",
    "    avg_time_to_delivery=('time_to_delivery', 'mean'),\n",
    "    proportion_late=('late_delivery', lambda x: (x > 0).mean())\n",
    ").reset_index()\n",
    "\n",
    "# Create a plot using Plotly\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add a bar for average Time to Delivery\n",
    "fig.add_trace(\n",
    "    go.Bar(x=monthly_delivery_stats['order_month'], y=monthly_delivery_stats['avg_time_to_delivery'], \n",
    "           name='Avg. Time to Delivery (days)'),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Add a line for the proportion of late deliveries\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly_delivery_stats['order_month'], y=monthly_delivery_stats['proportion_late'], \n",
    "               name='Proportion of Late Deliveries', mode='lines+markers', marker=dict(color='red')),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title='Proportion of Late Delivery vs Average Time to Delivery in Monthly Trends',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Average Time to Delivery (days)',\n",
    "    yaxis2_title='Proportion of Late Deliveries',\n",
    "    legend=dict(y=0.5, traceorder='reversed', font_size=16)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "grouped_data = merged_df.groupby(['order_month', 'late_delivery'])['product_weight_g'].count().reset_index()\n",
    "grouped_data = grouped_data.pivot(index='order_month', columns='late_delivery', values='product_weight_g').fillna(0)\n",
    "\n",
    "# Creating the bar for each 'late_delivery' status\n",
    "bars = []\n",
    "for late_delivery_status in grouped_data.columns:\n",
    "    bars.append(go.Bar(name=str(late_delivery_status),\n",
    "                       x=grouped_data.index,\n",
    "                       y=grouped_data[late_delivery_status]))\n",
    "\n",
    "# Creating the figure and adding the bars\n",
    "fig = go.Figure(data=bars)\n",
    "\n",
    "# Change the bar mode to stacked\n",
    "fig.update_layout(barmode='stack', \n",
    "                  title='Count of Product Weight by Month and Late Delivery Status',\n",
    "                  xaxis_title='Order Month',\n",
    "                  yaxis_title='Count of Product Weight')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "# Calculate the percentage of late deliveries by category\n",
    "late_deliveries_by_category = merged_df[merged_df['late_delivery'] == 1]['product_category_name_english'].value_counts()\n",
    "total_late_deliveries = late_deliveries_by_category.sum()\n",
    "late_deliveries_by_category_percent = (late_deliveries_by_category / total_late_deliveries).cumsum() * 100\n",
    "\n",
    "# Modifying the Pareto Chart to include lines for 80% and 20% thresholds\n",
    "\n",
    "# Recreating the Pareto Chart with modifications\n",
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "late_deliveries_by_category.plot(kind='bar', ax=ax, color='skyblue')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(late_deliveries_by_category_percent.index, late_deliveries_by_category_percent.values, color='red', marker='D', ms=7)\n",
    "ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "# Adding lines for the 80% and 20% thresholds\n",
    "ax2.axhline(80, color='green', linestyle='--', linewidth=2)\n",
    "# Identifying the point where cumulative percentage surpasses 80%\n",
    "category_80_idx = late_deliveries_by_category_percent[late_deliveries_by_category_percent >= 80].index[0]\n",
    "category_80_position = late_deliveries_by_category.index.get_loc(category_80_idx)\n",
    "\n",
    "ax.axvline(category_80_position, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.tick_params(axis='y', colors='skyblue')\n",
    "ax2.tick_params(axis='y', colors='red')\n",
    "ax.set_xlabel('Product Category')\n",
    "ax.set_ylabel('Number of Late Deliveries', color='skyblue')\n",
    "ax2.set_ylabel('Cumulative Percentage', color='red')\n",
    "plt.title('Pareto Chart of Late Deliveries by Product Category with 80/20 Threshold')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use above insight in targeted Marketing efforts by :\n",
    "Focus on improving the logistics and delivery processes for the product categories that significantly contribute to late deliveries, as they could negatively impact customer satisfaction.\n",
    "Develop specialized marketing campaigns that address and reassure timely delivery for these high-late-delivery categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total order value by category\n",
    "order_value_by_category = merged_df.groupby('product_category_name_english')['order_value'].sum()\n",
    "total_order_value = order_value_by_category.sum()\n",
    "order_value_by_category_percent = (order_value_by_category / total_order_value).cumsum() * 100\n",
    "\n",
    "# Correcting the approach for the Pareto Chart of Order Value by Product Category\n",
    "\n",
    "# Sorting the order values by category in descending order\n",
    "sorted_order_value_by_category = order_value_by_category.sort_values(ascending=False)\n",
    "cumulative_order_value_percent = sorted_order_value_by_category.cumsum() / total_order_value * 100\n",
    "\n",
    "# Recreating the Pareto Chart with the correct approach\n",
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "sorted_order_value_by_category.plot(kind='bar', ax=ax, color='green')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(cumulative_order_value_percent.index, cumulative_order_value_percent.values, color='red', marker='D', ms=7)\n",
    "ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "# Adding lines for the 80% threshold\n",
    "ax2.axhline(80, color='green', linestyle='--', linewidth=2)\n",
    "category_80_idx_corrected = cumulative_order_value_percent[cumulative_order_value_percent >= 80].index[0]\n",
    "category_80_position_corrected = cumulative_order_value_percent.index.get_loc(category_80_idx_corrected)\n",
    "\n",
    "ax.axvline(category_80_position_corrected, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.tick_params(axis='y', colors='orange')\n",
    "ax2.tick_params(axis='y', colors='red')\n",
    "ax.set_xlabel('Product Category')\n",
    "ax.set_ylabel('Total Order Value', color='orange')\n",
    "ax2.set_ylabel('Cumulative Percentage', color='red')\n",
    "plt.title('Pareto Chart of Order Value by Product Category with 80/20 Threshold')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareto Chart of Order Value by Product Category with 80/20 Threshold: A small number of categories generate most of the revenue, showing market focus areas or best-sellers.¶\n",
    "### We can use above insight in targeted Marketing efforts by :\n",
    "Allocate more budget to advertise the top-performing product categories that contribute most to your sales volume to maximize ROI.\n",
    "Create bundles or promotions that include high-value items with other products to increase the overall order value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdates\n",
    "\n",
    "# Preparing data for Control Chart: Calculate daily average time to delivery\n",
    "daily_delivery_times = merged_df.copy()\n",
    "daily_delivery_times['order_approved_at'] = pd.to_datetime(daily_delivery_times['order_approved_at'])\n",
    "daily_delivery_times.set_index('order_approved_at', inplace=True)\n",
    "daily_avg_delivery_time = daily_delivery_times['time_to_delivery'].resample('D').mean().dropna()\n",
    "\n",
    "# Control Chart calculations\n",
    "mean_delivery_time = daily_avg_delivery_time.mean()\n",
    "std_dev_delivery_time = daily_avg_delivery_time.std()\n",
    "upper_control_limit = mean_delivery_time + (std_dev_delivery_time * 3)\n",
    "lower_control_limit = mean_delivery_time - (std_dev_delivery_time * 3)\n",
    "\n",
    "# Plotting the Control Chart\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "daily_avg_delivery_time.plot(ax=ax, marker='o', linestyle='-', color='blue', markersize=4)\n",
    "ax.axhline(mean_delivery_time, color='green', linestyle='--')\n",
    "ax.axhline(upper_control_limit, color='red', linestyle='--')\n",
    "ax.axhline(lower_control_limit, color='red', linestyle='--')\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_title('Control Chart for Daily Average Time to Delivery')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Average Time to Delivery (Days)')\n",
    "ax.legend(['Daily Avg Time to Delivery', 'Mean', 'Upper Control Limit', 'Lower Control Limit'])\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Chart for Daily Average Time to Delivery: Delivery times are generally consistent, but spikes suggest occasional delays that could impact customer satisfaction.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the Variability of Time to Delivery Across Different Product Categories\n",
    "category_delivery_times = merged_df.groupby('product_category_name_english')['time_to_delivery'].mean().sort_values()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x=category_delivery_times.values, y=category_delivery_times.index, palette=\"viridis\")\n",
    "plt.title('Average Time to Delivery by Product Category')\n",
    "plt.xlabel('Average Time to Delivery (Days)')\n",
    "plt.ylabel('Product Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average satisfaction score over weeks\n",
    "merged_df['order_approved_at'] = pd.to_datetime(merged_df['order_approved_at'])\n",
    "merged_df['week_year'] = merged_df['order_approved_at'].dt.strftime('%Y-%U')\n",
    "\n",
    "# Calculating average satisfaction score over weeks\n",
    "weekly_satisfaction = merged_df.groupby('week_year')['satisfaction'].mean().reset_index()\n",
    "\n",
    "# Adding more features for analysis: Average time to delivery and order value per week\n",
    "weekly_features = merged_df.groupby('week_year').agg({\n",
    "    'time_to_delivery': 'mean',\n",
    "    'order_value': 'mean',\n",
    "    'satisfaction': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Additional feature: Number of Late Deliveries per week\n",
    "weekly_late_deliveries = merged_df.groupby('week_year')['late_delivery'].sum()\n",
    "\n",
    "# Normalize the additional features to compare them on the same scale as satisfaction scores\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "weekly_features_scaled = weekly_features.copy()\n",
    "weekly_features_scaled[['time_to_delivery', 'order_value', 'satisfaction']] = scaler.fit_transform(\n",
    "    weekly_features[['time_to_delivery', 'order_value', 'satisfaction']]\n",
    ")\n",
    "\n",
    "# Adding normalized number of late deliveries\n",
    "weekly_features_scaled['late_deliveries_normalized'] = scaler.fit_transform(weekly_late_deliveries.values.reshape(-1, 1))\n",
    "\n",
    "# Time to Delivery and Satisfaction Score\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(weekly_features_scaled['week_year'], weekly_features_scaled['satisfaction'], label='Satisfaction Score', color='red', marker='o')\n",
    "plt.plot(weekly_features_scaled['week_year'], weekly_features_scaled['time_to_delivery'], label='Time to Delivery', color='blue', linestyle='--')\n",
    "plt.title('Time to Delivery vs. Satisfaction Score Over Weeks')\n",
    "plt.xlabel('Week of the Year')\n",
    "plt.ylabel('Normalized Scores and Values')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to Delivery vs. Satisfaction Score: This graph emphasizes the relationship between delivery times and customer satisfaction, allowing us to identify patterns where longer or shorter delivery times might impact satisfaction levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Calculating the linear regression between Time to Delivery and Satisfaction Score\n",
    "slope, intercept, r_value, p_value, std_err = linregress(weekly_features_scaled['time_to_delivery'], weekly_features_scaled['satisfaction'])\n",
    "\n",
    "# Calculate the best fit line\n",
    "line = slope * weekly_features_scaled['time_to_delivery'] + intercept\n",
    "\n",
    "# Scatter Plot with Best Fit Line\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(weekly_features_scaled['time_to_delivery'], weekly_features_scaled['satisfaction'], color='blue', alpha=0.6)\n",
    "plt.plot(weekly_features_scaled['time_to_delivery'], line, color='red', label=f'Best Fit Line\\nR={r_value:.2f}, R²={r_value**2:.2f}')\n",
    "\n",
    "plt.title('Time to Delivery vs. Satisfaction Score with Best Fit Line')\n",
    "plt.xlabel('Normalized Time to Delivery')\n",
    "plt.ylabel('Normalized Satisfaction Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Score (R): The correlation score of -0.79 indicates a strong negative relationship between Time to Delivery and Satisfaction Score. This suggests that as the time to delivery increases, the satisfaction score tends to decrease, and vice versa.¶\n",
    "\n",
    "R² Value: The R² value of 0.62 means that approximately 62% of the variability in the satisfaction scores can be explained by the variability in the time to delivery. This is a substantial proportion, highlighting the significant impact of delivery time on customer satisfaction on a weekly level.\n",
    "These scores underscore the importance of efficient delivery processes as a key driver of customer satisfaction. Efforts to reduce delivery times could therefore be expected to have a positive effect on overall satisfaction scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying top 10 features with highest correlation with 'satisfaction'\n",
    "# Select only the numeric columns for correlation calculation\n",
    "numeric_cols = merged_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute the correlation matrix for numeric columns only\n",
    "corr_matrix = numeric_cols.corr()\n",
    "\n",
    "# Print the top 10 features correaltion score\n",
    "print(corr_matrix['satisfaction'].sort_values(ascending=False)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correlation threshold\n",
    "threshold = 0.05\n",
    "\n",
    "# Get the features with correlation greater than 7% or less than -7% with 'satisfaction'\n",
    "high_corr_features = corr_matrix.index[(corr_matrix['satisfaction'].abs() > threshold) & (corr_matrix.index != 'satisfaction')].tolist()\n",
    "\n",
    "# Print the highly correlated features\n",
    "print(high_corr_features)\n",
    "\n",
    "# check data types for top 10 features\n",
    "merged_df[high_corr_features].dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to take only 5 features\n",
    "top_4_features = ['payment_value', 'time_to_delivery', 'estimated_vs_actual_shipping', 'late_delivery']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Selecting only the top 6 features\n",
    "top_6_features = ['estimated_vs_actual_shipping', 'order_month', 'order_hour', 'price', 'payment_sequential', 'order_value', 'payment_installments']\n",
    "X = merged_df[top_4_features]\n",
    "y = merged_df['satisfaction']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Applying ColumnTransformer to preprocess the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, top_4_features)]\n",
    ")\n",
    "\n",
    "# Preprocessing the data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=50),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10, min_samples_split=10, min_samples_leaf=4),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to fit models, make predictions, and evaluate them\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Plotting confusion matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    evaluate_model(model, X_train_preprocessed, y_train, X_test_preprocessed, y_test, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Fewer trees to keep the model simpler\n",
    "    'max_depth': [3, 4, 5],          # Shallow trees to prevent overfitting\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # or another scoring metric\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "train_preds = best_model.predict(X_train_preprocessed)\n",
    "test_preds = best_model.predict(X_test_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initializing models\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# A function to fit models, make predictions, and evaluate them\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Plotting confusion matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'{model.__class__.__name__} Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{model.__class__.__name__} Classification Report:\")\n",
    "    print(class_report)\n",
    "    return model\n",
    "\n",
    "# Evaluating Logistic Regression\n",
    "evaluate_model(log_reg, X_train_preprocessed, y_train, X_test_preprocessed, y_test)\n",
    "\n",
    "# Evaluating Decision Tree\n",
    "evaluate_model(decision_tree, X_train_preprocessed, y_train, X_test_preprocessed, y_test)\n",
    "\n",
    "# Evaluating Random Forest\n",
    "evaluate_model(random_forest, X_train_preprocessed, y_train, X_test_preprocessed, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(true_values, predictions, set_name):\n",
    "    matrix = confusion_matrix(true_values, predictions)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'{set_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Function to print classification report\n",
    "def print_classification_report(true_values, predictions, set_name):\n",
    "    report = classification_report(true_values, predictions)\n",
    "    print(f\"{set_name} Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "# Visualize and print reports for both sets\n",
    "plot_confusion_matrix(y_train, train_preds, \"Training\")\n",
    "print_classification_report(y_train, train_preds, \"Training\")\n",
    "\n",
    "plot_confusion_matrix(y_test, test_preds, \"Testing\")\n",
    "print_classification_report(y_test, test_preds, \"Testing\")\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final pipeline using the best model\n",
    "final_pipeline = Pipeline(steps=[('preprocessing', preprocessor),\n",
    "    ('classifier', xgb_model)\n",
    "])\n",
    "\n",
    "final_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to your data\n",
    "final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Save pipeline as pkl file\n",
    "import joblib\n",
    "\n",
    "joblib.dump(final_pipeline, 'final_ECommerce_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('final_ECommerce_model.pkl')\n",
    "\n",
    "import random\n",
    "\n",
    "class SatisfactionFinder:\n",
    "    def __init__(self, model, preprocessor, features, trials=50):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.features = features\n",
    "        self.trials = trials\n",
    "\n",
    "    def random_input(self):\n",
    "        \"\"\"Generate a random input within plausible ranges for each feature.\"\"\"\n",
    "        ranges = {\n",
    "            'estimated_vs_actual_shipping': (-189, 146),\n",
    "            'time_to_delivery': (-7, 208),  # Updated with correct range\n",
    "            'payment_value': (0.0, 13664.08),  # Updated with correct range\n",
    "            'order_item_id': (1.0, 21.0),  # Updated with correct range\n",
    "            'late_delivery': (0, 1)  # Binary feature\n",
    "        }\n",
    "\n",
    "        # Generate a random value within each range\n",
    "        return {feature: random.uniform(*ranges[feature]) if isinstance(ranges[feature][0], float)\n",
    "                else random.randint(*ranges[feature]) for feature in self.features}\n",
    "\n",
    "    def find_not_satisfied(self):\n",
    "        \"\"\"Loop to find a set of values that predict 'Not Satisfied'.\"\"\"\n",
    "        for _ in range(self.trials):\n",
    "            # Generate random input\n",
    "            user_data = self.random_input()\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            input_df = pd.DataFrame([user_data])\n",
    "\n",
    "            # Preprocess and predict\n",
    "            input_preprocessed = self.preprocessor.transform(input_df)\n",
    "            prediction = self.model.predict(input_preprocessed)\n",
    "\n",
    "            # Check if prediction is 'Not Satisfied'\n",
    "            if prediction[0] == 0:\n",
    "                return user_data, \"Not Satisfied\"\n",
    "\n",
    "        return None, \"Not found\"\n",
    "\n",
    "# Assuming xgb_model, preprocessor, and top_6_features are previously defined\n",
    "finder = SatisfactionFinder(xgb_model, preprocessor, ['estimated_vs_actual_shipping', 'time_to_delivery', 'payment_value', 'late_delivery'], trials=200)\n",
    "\n",
    "# Find a 'Not Satisfied' prediction\n",
    "user_data, result = finder.find_not_satisfied()\n",
    "\n",
    "print(\"User Data:\", user_data)\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(pd.DataFrame([{\n",
    "    'estimated_vs_actual_shipping': 130,\n",
    "    'time_to_delivery': 133, \n",
    "    'payment_value': 9591,\n",
    "    'late_delivery': 1 \n",
    "}], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(pd.DataFrame([{\n",
    "    'estimated_vs_actual_shipping': 5,\n",
    "    'time_to_delivery': 7,\n",
    "    'payment_value': 300,\n",
    "    'late_delivery': 0 \n",
    "}], dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ECB.py\n",
    "\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load your trained pipeline\n",
    "model = joblib.load('final_ECommerce_model.pkl')\n",
    "\n",
    "# Define the structure of your app\n",
    "def main():\n",
    "    st.title('Customer Satisfaction Prediction App')\n",
    "\n",
    "   # Define inputs with appropriate ranges and default values based on your data\n",
    "    estimated_vs_actual_shipping = st.number_input('Estimated vs Actual Shipping Days', min_value=-189, max_value=146, value=11)\n",
    "    time_to_delivery = st.number_input('Time to Delivery', min_value=-7, max_value=208, value=9)\n",
    "    payment_value = st.number_input('Payment Value', min_value=0.0, max_value=13664.08, value=107.78)\n",
    "    late_delivery = st.number_input('Late Delivery', min_value=0, max_value=1, value=0) \n",
    "\n",
    "# Prediction button\n",
    "    if st.button('Predict Satisfaction'):\n",
    "        # Create an array with the input data\n",
    "        # Make sure all inputs are included in the array in the correct order\n",
    "        input_data = np.array([[estimated_vs_actual_shipping, time_to_delivery, payment_value, late_delivery]])\n",
    "\n",
    "        # Get the prediction\n",
    "        prediction = model.predict(input_data)\n",
    "\n",
    "        # Output the prediction\n",
    "        if prediction[0] == 1:\n",
    "            st.success('The customer is satisfied.')\n",
    "        else:\n",
    "            st.error('The customer is not satisfied')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Custom CSS to increase the font size and prevent collapsing\n",
    "style = \"\"\"\n",
    "<style>\n",
    ".widget-label { min-width: 25ex !important; }\n",
    ".widget-label p { font-size: 16px !important; }\n",
    ".slider-width { width: 100% !important; } /* Adjust the width as needed */\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Display the custom CSS\n",
    "display(HTML(style))\n",
    "\n",
    "# Load your trained model\n",
    "model = joblib.load('final_ECommerce_model.pkl')\n",
    "\n",
    "# Define layout for the sliders\n",
    "slider_layout = widgets.Layout(width='500px')  # Adjust the width as needed\n",
    "\n",
    "# Create input widgets for user input with updated ranges and types\n",
    "estimated_vs_actual_shipping = widgets.IntSlider(\n",
    "    value=11, min=-189, max=146, step=1,\n",
    "    description='Estimated vs Actual Shipping Days:',\n",
    "    style={'description_width': 'initial'},  # Prevent collapsing\n",
    "    layout=slider_layout\n",
    ")\n",
    "\n",
    "time_to_delivery = widgets.IntSlider(\n",
    "    value=9, min=-7, max=208, step=1,\n",
    "    description='Time to Delivery:',\n",
    "    style={'description_width': 'initial'},  # Prevent collapsing\n",
    "    layout=slider_layout\n",
    ")\n",
    "\n",
    "payment_value = widgets.FloatSlider(\n",
    "    value=107.78, min=0.0, max=13664.08, step=0.01,\n",
    "    description='Payment Value:',\n",
    "    style={'description_width': 'initial'},  # Prevent collapsing\n",
    "    layout=slider_layout\n",
    ")\n",
    "\n",
    "late_delivery = widgets.IntSlider(\n",
    "    value=0, min=0, max=1, step=1,\n",
    "    description='Late Delivery:',\n",
    "    style={'description_width': 'initial'},  # Prevent collapsing\n",
    "    layout=slider_layout\n",
    ")\n",
    "\n",
    "# Create a button widget for making predictions\n",
    "predict_button = widgets.Button(description='Predict Satisfaction')\n",
    "\n",
    "# Define a function to make predictions and display the result\n",
    "def predict_satisfaction(b):\n",
    "    # Collect values from widgets and create a DataFrame for prediction\n",
    "    user_input = pd.DataFrame({\n",
    "        'estimated_vs_actual_shipping': [estimated_vs_actual_shipping.value],\n",
    "        'time_to_delivery': [time_to_delivery.value],\n",
    "        'payment_value': [payment_value.value],\n",
    "        'late_delivery': [late_delivery.value]\n",
    "    })\n",
    "\n",
    "    # Predict using the model\n",
    "    prediction = model.predict(user_input)\n",
    "    \n",
    "    # Update the result label based on the prediction\n",
    "    if prediction[0] == 1:\n",
    "        result_label.value = 'The customer is satisfied.'\n",
    "    else:\n",
    "        result_label.value = 'The customer is not satisfied.'\n",
    "\n",
    "# Attach the predict_satisfaction function to the button's click event\n",
    "predict_button.on_click(predict_satisfaction)\n",
    "\n",
    "# Create a label widget to display the prediction result\n",
    "result_label = widgets.Label()\n",
    "\n",
    "# Display the input widgets and the result label\n",
    "input_widgets = [\n",
    "    estimated_vs_actual_shipping,\n",
    "    time_to_delivery,\n",
    "    payment_value,\n",
    "    late_delivery,\n",
    "    predict_button,\n",
    "    result_label  # This should also be included in the list to be displayed\n",
    "]\n",
    "\n",
    "for widget in input_widgets:\n",
    "    display(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of customer behavior \n",
    "1. **Complex:** occurs when customers invest significant time and effort in evaluating products before making a purchase. High-involvement products, such as cars or expensive electronics, often trigger this type of behavior.\n",
    "2. **Dissonance-reducing**: takes place when customers experience post-purchase anxiety or uncertainty about their decision. This can arise when consumers feel that they had to make a decision quickly, without sufficient time to weigh the pros and cons, or if their choice was informed by limited information.\n",
    "3. **Habitual buying:** characterized by consumers relying on routines and habits when making purchasing decisions. This type of behavior is commonly found in less involving product categories, such as groceries or personal care items, where consumers are not as inclined to research products extensively before purchase. \n",
    "4. **Variety seeking:** arises when customers actively seek new experiences, products, or brands, even if satisfied with their current choices. This behavior typically occurs in categories where products are low-involvement, low-cost commodities, and consumers feel minimal risk in trying new options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
